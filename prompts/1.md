## UI shell
Goal:
Build the global UI shell using expo-router with bottom tabs:
- Home
- Add Journal
- Profile

Context:
This is a text-first AI journaling app. MVP excludes audio. We want stable navigation before implementing feature logic.

Constraints:
- Expo + TypeScript + expo-router.
- Keep dependencies minimal.
- Tabs must be stable so parallel threads can build features without editing routing files.
- "Add Journal" should behave like a compose action: create/resume a session and navigate to the journaling screen.

Deliverables:
1) Navigation:
- app/_layout.tsx root stack with onboarding gate
- app/(tabs)/_layout.tsx bottom tabs: Home, Add Journal, Profile
- onboarding group: app/(onboarding)/index.tsx
- journaling session route: app/(tabs)/home/journal/[id].tsx (placeholder for now)

2) Screens:
- Home placeholder (daily view skeleton + recent journals placeholder list)
- Add placeholder that redirects to a new session route (stub session id generator)
- Profile placeholder (settings/profile sections)

3) Shared UI:
- src/theme/ tokens
- src/ui/ Button/Card/Text components

Acceptance criteria:
- App launches into onboarding if needsOnboarding flag is true, else tabs.
- Tabs navigate correctly.
- Tapping Add Journal creates a mock session id and routes to the journal session screen.
- No real journaling logic yet.

Verification:
- Provide run steps and a small manual checklist.

Files expected to change:
Only navigation, placeholder screens, and shared UI primitives. Do not implement full journaling flow yet.

---

## Journaling Session UI

Goal:
Implement the Journaling Session screen UX from the architecture:
- Date header + Complete button
- Large “Current Draft” text area
- AI Question card + “Next question” button
- Optional Advisor Suggestions panel (collapsed by default)

Context:
Use the existing mock AI mode:
- Next question comes from local Question Database
- Validate “answered” by heuristic until backend exists

Constraints:
- No new libraries unless required.
- Keep components small and reusable.

Deliverables:
- /journal screen UI fully working
- State machine: Drafting -> Questioning -> Completed
- Persist draft and questions to Supabase (cloud-first); local storage only for short-lived drafts

Acceptance criteria:
- “Next question” adds a question to the thread
- “Complete” triggers Extractor (mock) and saves a DailySummary
- No UI freezes when typing

Verification:
- Manual smoke test steps to confirm flow
---
## Data Layer + Schema (Supabase)
Goal:
Implement persistence using Supabase Postgres for:
- Journal entries/sessions
- AI questions asked in a session
- Extracted daily summaries
- ME database blobs (profile/state/patterns/trust)

Constraints:
- Keep schema simple: use a few tables + JSON columns where useful.
- Provide typed repository functions.
- Include migrations strategy (SQL files or Supabase migrations).
- Cloud-first: store all journaling data in Supabase; local storage only for short-lived drafts.

Deliverables:
- src/data/supabaseClient.ts setup (or equivalent)
- repositories: journalRepo, meRepo
- types + runtime validators for JSON blobs

Acceptance criteria:
- Create/read/list journal entries works
- History screen reads from Supabase repo

Verification:
- Add a small script/dev screen to seed/read data (or a SQL seed file)
---
## Backend “AI Pipeline” stub (Edge Function or Node)
Goal:
Create a backend endpoint stub that the mobile app can call:
POST /ai/runPipeline

Behavior:
Given {draftText, meContext, lastQuestion?, sessionHistory?}
Return:
- nextQuestion (string)
- extracted: {dailySummary, detectedSignals, patternUpdates, trustUpdates}
- advice: 0-3 suggestions grounded in evidence snippets

Constraints:
- Do NOT put secrets in mobile client.
- For now, implement a mocked response generator plus a clear TODO for real LLM calls.
- Return strict JSON with a schema.

Deliverables:
- Backend folder scaffold
- Endpoint implementation + JSON schema
- Mobile client api wrapper (src/api/ai.ts)

Verification:
- Provide curl example and expected response
---
## Runtime Prompt Library (for later LLM wiring)
Goal:
Write the runtime LLM prompt templates (as plain text files) for:
- Context Reader
- Question Validator
- Follow-up Generator
- New Question Generator
- Extractor
- Advisor

Constraints:
- Each prompt must:
  - Ask for JSON-only output
  - Include a schema
  - Require evidence quotes from the journal for any claims
  - Include safety constraints (no medical diagnosis, no certainty, encourage professional help when relevant)

Deliverables:
- docs/prompts-runtime.md explaining each module
- src/ai/prompts/*.ts exporting strings + schemas

Acceptance criteria:
- Prompts are modular and composable
- Output schemas align across modules
